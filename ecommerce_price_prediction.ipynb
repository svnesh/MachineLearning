{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mhack_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHDePsWGheJU",
        "outputId": "ec6e4aee-2295-47e4-cd09-12c3ff073d55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfP1TMQThj6m"
      },
      "source": [
        "root_path = \"/content/drive/My Drive/MachineHack_1/Inputs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-A_j0khl8k"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cmE7wthm33"
      },
      "source": [
        "train = pd.read_csv(os.path.join(root_path, 'Train.csv'))\n",
        "test = pd.read_csv(os.path.join(root_path, 'Test.csv'))\n",
        "#df_full = pd.concat([train,test], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xNfawyhm0V"
      },
      "source": [
        "train['prod_return'] = np.where(train.Quantity < 0, 1, 0)\n",
        "test['prod_return'] = np.where(test.Quantity < 0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV1J3KqPhmwU"
      },
      "source": [
        "train.loc[train.Quantity < 0, 'Quantity'] = 0\n",
        "test.loc[test.Quantity < 0, 'Quantity'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD0ZANzOhmqU"
      },
      "source": [
        "train['UnitPrice'] = np.log1p(train['UnitPrice'])\n",
        "#\n",
        "train['Quantity'] = np.log1p(train['Quantity'])\n",
        "test['Quantity'] = np.log1p(test['Quantity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfBgUKltirKE"
      },
      "source": [
        "'''\n",
        "train['customer_invoice_count'] = train.groupby(['CustomerID','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "test['customer_invoice_count'] = test.groupby(['CustomerID','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "#\n",
        "test['customer_stock_count'] = test.groupby(['CustomerID','StockCode'])['StockCode'].transform('count')\n",
        "train['customer_stock_count'] = train.groupby(['CustomerID','StockCode'])['StockCode'].transform('count')\n",
        "#\n",
        "train['stock_quantity_sum'] = train.groupby('StockCode')['Quantity'].transform('sum')\n",
        "test['stock_quantity_sum'] = test.groupby('StockCode')['Quantity'].transform('sum')\n",
        "#\n",
        "train['country_customer_count'] = train.groupby(['Country','CustomerID'])['CustomerID'].transform('count')\n",
        "test['country_customer_count'] = test.groupby(['Country','CustomerID'])['CustomerID'].transform('count')\n",
        "#\n",
        "train['country_stock_count'] = train.groupby(['Country','StockCode'])['StockCode'].transform('count')\n",
        "test['country_stock_count'] = test.groupby(['Country','StockCode'])['StockCode'].transform('count')\n",
        "#\n",
        "train['country_quantity_sum'] = train.groupby('Country')['Quantity'].transform('sum')\n",
        "test['country_quantity_sum'] = test.groupby('Country')['Quantity'].transform('sum')\n",
        "#\n",
        "train['invdate_quantity_sum'] = train.groupby('InvoiceDate')['Quantity'].transform('sum')\n",
        "test['invdate_quantity_sum'] = test.groupby('InvoiceDate')['Quantity'].transform('sum')\n",
        "#\n",
        "train['Invdate'] = pd.to_datetime(train['InvoiceDate']).dt.date\n",
        "test['Invdate'] = pd.to_datetime(test['InvoiceDate']).dt.date\n",
        "#\n",
        "train['invdate_invno_count'] = train.groupby(['Invdate','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "test['invdate_invno_count'] = test.groupby(['Invdate','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "#\n",
        "train['invdate_stock_count'] = train.groupby(['Invdate','StockCode'])['StockCode'].transform('count')\n",
        "test['invdate_stock_count'] = test.groupby(['Invdate','StockCode'])['StockCode'].transform('count')\n",
        "#\n",
        "train['invdate_customer_count'] = train.groupby(['Invdate','CustomerID'])['CustomerID'].transform('count')\n",
        "test['invdate_customer_count'] = test.groupby(['Invdate','CustomerID'])['CustomerID'].transform('count')\n",
        "#\n",
        "train['Invtime'] = pd.to_datetime(train['InvoiceDate']).dt.hour\n",
        "test['Invtime'] = pd.to_datetime(test['InvoiceDate']).dt.hour\n",
        "#\n",
        "train['invtime_invno_count'] = train.groupby(['Invtime','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "test['invtime_invno_count'] = test.groupby(['Invtime','InvoiceNo'])['InvoiceNo'].transform('count')\n",
        "#\n",
        "train['invtime_stock_count'] = train.groupby(['Invtime','StockCode'])['StockCode'].transform('count')\n",
        "test['invtime_stock_count'] = test.groupby(['Invtime','StockCode'])['StockCode'].transform('count')\n",
        "#\n",
        "train['invtime_customer_count'] = train.groupby(['Invtime','CustomerID'])['CustomerID'].transform('count')\n",
        "test['invtime_customer_count'] = test.groupby(['Invtime','CustomerID'])['CustomerID'].transform('count')\n",
        "#\n",
        "train['inv_stock_count'] = train.groupby(['InvoiceNo','StockCode'])['StockCode'].transform('count')\n",
        "test['inv_stock_count'] = test.groupby(['InvoiceNo','StockCode'])['StockCode'].transform('count')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqytQ7JNirPk"
      },
      "source": [
        "def getDateTime(df):\n",
        "  df1 = pd.to_datetime(df['InvoiceDate'])\n",
        "  df['inv_year'] = df1.dt.year\n",
        "  df['inv_month'] = df1.dt.month\n",
        "  df['inv_day'] = df1.dt.day\n",
        "  df['inv_dow'] = df1.dt.dayofweek\n",
        "  df['inv_hr'] = df1.dt.hour\n",
        "  df['inv_min'] = df1.dt.minute\n",
        "  df['inv_monthst'] = df1.dt.is_month_start.astype('int')\n",
        "  df['inv_monthed'] = df1.dt.is_month_end.astype('int')\n",
        "  df['inv_yearst'] = df1.dt.is_year_start.astype('int')\n",
        "  df['inv_yeared'] = df1.dt.is_year_end.astype('int')\n",
        "  #df['inv_sec'] = df1.dt.second\n",
        "  #return df\n",
        "getDateTime(train)\n",
        "getDateTime(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVyHgnRiirNE"
      },
      "source": [
        "df1 = train[['InvoiceNo', 'StockCode','Quantity']]\n",
        "df2 = df1.append(test[['InvoiceNo', 'StockCode','Quantity']])\n",
        "df3 = pd.DataFrame(df2.groupby(['InvoiceNo','StockCode'])['Quantity'].mean())\n",
        "df3 = df3.reset_index()\n",
        "df3 = df3.sort_values('Quantity')\n",
        "df3['StockCode_group'] = df3[['InvoiceNo']].astype(str)+'_group'\n",
        "df3['group'] = np.arange(len(df3))\n",
        "stock_dict = dict(zip(df3.StockCode_group, df3.group))\n",
        "train['StockCode_group'] = train[['InvoiceNo']].astype(str)+'_group'\n",
        "test['StockCode_group'] = test[['InvoiceNo']].astype(str)+'_group'\n",
        "train['StockCode_class'] = train.StockCode_group.map(stock_dict)\n",
        "test['StockCode_class'] = test.StockCode_group.map(stock_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQqzxMNiqv5S"
      },
      "source": [
        "df1 = train[['StockCode', 'CustomerID','Quantity']]\n",
        "df2 = df1.append(test[['StockCode', 'CustomerID','Quantity']])\n",
        "df3 = pd.DataFrame(df2.groupby(['StockCode','CustomerID'])['Quantity'].mean())\n",
        "df3 = df3.reset_index()\n",
        "df3 = df3.sort_values('Quantity')\n",
        "df3['Customer_group'] = df3[['StockCode']].astype(str)+'_group'\n",
        "df3['group'] = np.arange(len(df3))\n",
        "cust_dict = dict(zip(df3.Customer_group, df3.group))\n",
        "train['Customer_group'] = train[['StockCode']].astype(str)+'_group'\n",
        "test['Customer_group'] = test[['StockCode']].astype(str)+'_group'\n",
        "train['Customer_class'] = train.Customer_group.map(cust_dict)\n",
        "test['Customer_class'] = test.Customer_group.map(cust_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6QW82TCBCHi"
      },
      "source": [
        "train['InvDate'] = pd.to_datetime(train['InvoiceDate']).dt.date\n",
        "test['InvDate'] = pd.to_datetime(test['InvoiceDate']).dt.date\n",
        "df1 = train[['StockCode', 'InvDate','Quantity']]\n",
        "df2 = df1.append(test[['StockCode', 'InvDate','Quantity']])\n",
        "df3 = pd.DataFrame(df2.groupby(['StockCode','InvDate'])['Quantity'].mean())\n",
        "df3 = df3.reset_index()\n",
        "df3 = df3.sort_values('Quantity')\n",
        "df3['Invdate_group'] = df3[['StockCode']].astype(str)+'_group'\n",
        "df3['group'] = np.arange(len(df3))\n",
        "inv_dict = dict(zip(df3.Invdate_group, df3.group))\n",
        "train['InvDate_group'] = train[['StockCode']].astype(str)+'_group'\n",
        "test['InvDate_group'] = test[['StockCode']].astype(str)+'_group'\n",
        "train['InvDate_class'] = train.InvDate_group.map(inv_dict)\n",
        "test['InvDate_class'] = test.InvDate_group.map(inv_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM6bAj1VItkJ"
      },
      "source": [
        "'''\n",
        "#after 27.07532\n",
        "df1 = train[['CustomerID', 'InvoiceNo','Quantity']]\n",
        "df2 = df1.append(test[['CustomerID', 'InvoiceNo','Quantity']])\n",
        "df3 = pd.DataFrame(df2.groupby(['CustomerID','InvoiceNo'])['Quantity'].mean())\n",
        "df3 = df3.reset_index()\n",
        "df3 = df3.sort_values('Quantity')\n",
        "df3['Invoice_group'] = df3[['CustomerID']].astype(str)+'_group'\n",
        "df3['group'] = np.arange(len(df3))\n",
        "invoice_dict = dict(zip(df3.Invoice_group, df3.group))\n",
        "train['Invoice_group'] = train[['CustomerID']].astype(str)+'_group'\n",
        "test['Invoice_group'] = test[['CustomerID']].astype(str)+'_group'\n",
        "train['Invoice_class'] = train.Invoice_group.map(invoice_dict)\n",
        "test['Invoice_class'] = test.Invoice_group.map(invoice_dict)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bACejTk4LP2G"
      },
      "source": [
        "'''\n",
        "#after 27.07532\n",
        "train['Invhour'] = pd.to_datetime(train['InvoiceDate']).dt.hour\n",
        "test['Invhour'] = pd.to_datetime(test['InvoiceDate']).dt.hour\n",
        "df1 = train[['CustomerID', 'Invhour','Quantity']]\n",
        "df2 = df1.append(test[['CustomerID', 'Invhour','Quantity']])\n",
        "df3 = pd.DataFrame(df2.groupby(['CustomerID','Invhour'])['Quantity'].mean())\n",
        "df3 = df3.reset_index()\n",
        "df3 = df3.sort_values('Quantity')\n",
        "df3['Invhour_group'] = df3[['CustomerID']].astype(str)+'_group'\n",
        "df3['group'] = np.arange(len(df3))\n",
        "invhour_dict = dict(zip(df3.Invhour_group, df3.group))\n",
        "train['InvHour_group'] = train[['CustomerID']].astype(str)+'_group'\n",
        "test['InvHour_group'] = test[['CustomerID']].astype(str)+'_group'\n",
        "train['InvHour_class'] = train.InvHour_group.map(invhour_dict)\n",
        "test['InvHour_class'] = test.InvHour_group.map(invhour_dict)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z_H-gZQirHN"
      },
      "source": [
        "#pd.to_pickle(train, os.path.join(root_path, 'train_new1.pkl'))\n",
        "#pd.to_pickle(test, os.path.join(root_path, 'test_new1.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJqrCBn_0-dm"
      },
      "source": [
        "#train = pd.read_pickle(os.path.join(root_path, 'train_new1.pkl'))\n",
        "#test = pd.read_pickle(os.path.join(root_path, 'test_new1.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "milc_ADJuc7w"
      },
      "source": [
        "def replaceZero(df):\n",
        "  stock_list = df.loc[df['UnitPrice'] == 0, 'StockCode']\n",
        "  for s in stock_list:\n",
        "    m1 = ((df['UnitPrice'] == 0) & (df['StockCode'] == s))\n",
        "    df.loc[m1, 'UnitPrice'] = df.loc[df['StockCode'] == s, 'UnitPrice'].mean()\n",
        "\n",
        "replaceZero(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3nQWxKDuc_I"
      },
      "source": [
        "train['inv_year'] = train['inv_year'].map({2011:0, 2010:1})\n",
        "test['inv_year'] = test['inv_year'].map({2011:0, 2010:1}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQEVstdCuc3p"
      },
      "source": [
        "def add_noise(series, noise_level):\n",
        "  return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "\n",
        "def target_encode(trn_series=None, test_series=None, target=None, \n",
        "                  min_samples_leaf=1, smoothing=1, noise_level=0):\n",
        "  assert len(trn_series) == len(target)\n",
        "  assert trn_series.name == test_series.name\n",
        "  temp = pd.concat([trn_series, target], axis=1)\n",
        "  averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean','count'])\n",
        "  smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "  prior = target.mean()\n",
        "  averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "  averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "  ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name), \n",
        "                          averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "                          on=trn_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "  ft_trn_series.index = trn_series.index\n",
        "  ft_test_series = pd.merge(test_series.to_frame(test_series.name), \n",
        "                            averages.reset_index().rename(columns={'index':target.name, target.name: 'average'}),\n",
        "                            on=test_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "  ft_test_series.index = test_series.index\n",
        "  return add_noise(ft_trn_series, noise_level), add_noise(ft_test_series, noise_level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBwY3ZU2VJvS"
      },
      "source": [
        "'''\n",
        "trn_invoice_class, tst_invoice_class = target_encode(train[\"Invoice_class\"],\n",
        "                         test[\"Invoice_class\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_invhour_class, tst_invhour_class = target_encode(train[\"InvHour_class\"],\n",
        "                         test[\"InvHour_class\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "                         '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdISz5U6ulrh"
      },
      "source": [
        "trn_stockcode_class, tst_stockcode_class = target_encode(train[\"StockCode_class\"],\n",
        "                         test[\"StockCode_class\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_customer_class, tst_customer_class = target_encode(train[\"Customer_class\"],\n",
        "                         test[\"Customer_class\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_invdate_class, tst_invdate_class = target_encode(train[\"InvDate_class\"],\n",
        "                         test[\"InvDate_class\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_country, tst_country = target_encode(train[\"Country\"],\n",
        "                         test[\"Country\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_inv_month, tst_inv_month = target_encode(train[\"inv_month\"],\n",
        "                         test[\"inv_month\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_inv_day, tst_inv_day = target_encode(train[\"inv_day\"],\n",
        "                         test[\"inv_day\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_inv_dow, tst_inv_dow = target_encode(train[\"inv_dow\"],\n",
        "                         test[\"inv_dow\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_inv_hr, tst_inv_hr = target_encode(train[\"inv_hr\"],\n",
        "                         test[\"inv_hr\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)\n",
        "trn_inv_min, tst_inv_min = target_encode(train[\"inv_min\"],\n",
        "                         test[\"inv_min\"],\n",
        "                         target=train.UnitPrice,\n",
        "                         min_samples_leaf=100,\n",
        "                         smoothing=20,\n",
        "                         noise_level=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TEf7b_nuo9o"
      },
      "source": [
        "train_encoded = pd.concat([trn_stockcode_class,trn_customer_class,trn_invdate_class,\n",
        "                           trn_country,trn_inv_month,\n",
        "                           trn_inv_day,trn_inv_dow,trn_inv_hr,trn_inv_min], axis=1)\n",
        "test_encoded = pd.concat([tst_stockcode_class,tst_customer_class,tst_invdate_class,\n",
        "                          tst_country,tst_inv_month,\n",
        "                           tst_inv_day,tst_inv_dow,tst_inv_hr,tst_inv_min], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QBMYKyJ4Z0g",
        "outputId": "3f074421-23e4-48f9-eccf-6acbb727a38b"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
              "       'UnitPrice', 'CustomerID', 'Country', 'prod_return', 'inv_year',\n",
              "       'inv_month', 'inv_day', 'inv_dow', 'inv_hr', 'inv_min', 'inv_monthst',\n",
              "       'inv_monthed', 'inv_yearst', 'inv_yeared', 'StockCode_group',\n",
              "       'StockCode_class', 'Customer_group', 'Customer_class', 'InvDate',\n",
              "       'InvDate_group', 'InvDate_class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v12tk1Vuopo"
      },
      "source": [
        "col_to_drop = ['InvoiceNo', 'StockCode','InvoiceDate','CustomerID',\n",
        "               'Country','StockCode_group', 'StockCode_class',\n",
        "               'Customer_group','Customer_class','InvDate_group','InvDate_class',\n",
        "               'InvDate','inv_month', 'inv_day', 'inv_dow', 'inv_hr', 'inv_min']\n",
        "train_final = pd.concat([train, train_encoded], axis=1).reset_index(drop=True).drop(columns=col_to_drop, axis=1)\n",
        "test_final = pd.concat([test, test_encoded], axis=1).reset_index(drop=True).drop(columns=col_to_drop, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sc4h8RGRRON",
        "outputId": "e3b4c428-12b6-433f-b257-8f3f96353cea"
      },
      "source": [
        "train_final.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Description', 'Quantity', 'UnitPrice', 'prod_return', 'inv_year',\n",
              "       'inv_monthst', 'inv_monthed', 'inv_yearst', 'inv_yeared',\n",
              "       'StockCode_class_mean', 'Customer_class_mean', 'InvDate_class_mean',\n",
              "       'Country_mean', 'inv_month_mean', 'inv_day_mean', 'inv_dow_mean',\n",
              "       'inv_hr_mean', 'inv_min_mean'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuZm1eyjSAEx",
        "outputId": "ebe558ef-6847-4fff-da82-8b6adee65500"
      },
      "source": [
        "test_final.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Description', 'Quantity', 'prod_return', 'inv_year', 'inv_monthst',\n",
              "       'inv_monthed', 'inv_yearst', 'inv_yeared', 'StockCode_class_mean',\n",
              "       'Customer_class_mean', 'InvDate_class_mean', 'Country_mean',\n",
              "       'inv_month_mean', 'inv_day_mean', 'inv_dow_mean', 'inv_hr_mean',\n",
              "       'inv_min_mean'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6LGx5pFuwGg"
      },
      "source": [
        "X = train_final.drop('UnitPrice', axis=1)\n",
        "y = train_final['UnitPrice']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQLl8j7suv-r"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "rs = RobustScaler()\n",
        "transformer = rs.fit(X)\n",
        "train_scaled = transformer.transform(X)\n",
        "test_scaled = transformer.transform(test_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xsGz7lTu3RQ"
      },
      "source": [
        "X_final = pd.DataFrame(train_scaled, columns=test_final.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXMq6BUdu65A"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scxfvNm_u82w",
        "outputId": "dd307c31-58d5-4355-dd32-a5f7de7d29d8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
        "print(f'Xtrain: {X_train.shape}')\n",
        "print(f'ytrain: {y_train.shape}')\n",
        "print(f'Xtest: {X_test.shape}')\n",
        "print(f'ytest: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xtrain: (227824, 17)\n",
            "ytrain: (227824,)\n",
            "Xtest: (56956, 17)\n",
            "ytest: (56956,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ2GDrRrvB3w",
        "outputId": "01b3ac5d-773e-4b63-c0e8-a77f7c737b62"
      },
      "source": [
        "rfr = RandomForestRegressor()\n",
        "rfr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX9taKBavLDg",
        "outputId": "00d98b82-0737-4fc1-d8f5-2a7cfcb68260"
      },
      "source": [
        "r2_train = float(format(rfr.score(X_train, y_train), '.3f'))\n",
        "r2_test = float(format(rfr.score(X_test, y_test), '.3f'))\n",
        "print(f'r2_train randomforest {r2_train}')\n",
        "print(f'r2_test randomforest {r2_test}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2_train randomforest 0.99\n",
            "r2_test randomforest 0.927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMWk2R2A1N7H",
        "outputId": "23f9076f-f80c-4ee9-fbe2-6c8962b3ba71"
      },
      "source": [
        "predictions = rfr.predict(X_test)\n",
        "errors = abs(predictions - y_test)\n",
        "mape = 100 * np.mean(errors / y_test)\n",
        "accuracy = 100 - mape\n",
        "print('Model Performance')\n",
        "print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "print('Accuracy = {:0.2f}%.'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance\n",
            "Average Error: 0.0666 degrees.\n",
            "Accuracy = 89.75%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDJEt2Tj-Lrb",
        "outputId": "101bd10e-1105-4aa1-8573-741a5664ad61"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, predictions))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.1651034828022791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qqJVOdf-6Xq",
        "outputId": "e4b2a248-b71e-4bcb-b56b-a93f050bd9b9"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print(f'r2_te: {r2_score(y_test, predictions)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2_te: 0.9200344830706569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JhiVFq2yO4h"
      },
      "source": [
        "X_te_final = pd.DataFrame(test_scaled, columns=test_final.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EAblte6yVbv"
      },
      "source": [
        "final_result = rfr.predict(X_te_final)\n",
        "#final_df = pd.DataFrame({'UnitPrice':final_result})\n",
        "sub_df = pd.DataFrame({'UnitPrice': np.expm1(final_result)})\n",
        "sub_df.to_csv(os.path.join(root_path, 'submit-17.csv'), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}